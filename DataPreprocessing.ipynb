{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haticeeakgull/Smart-Parking-Lot-System-/blob/main/DataPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RysJkUHz2lVS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "# --- Google Drive Bağlantısı (Colab için Gerekli) ---\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from meteostat import Point, Daily, Hourly\n",
        "from datetime import datetime ,timedelta\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BQbDCvaZ4X73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Düzeltilmiş Dosya Yolu\n",
        "# Klasörünüzün ismini buraya tam olarak yazmalısınız (örneğin: 'LizbonParkVeri')\n",
        "# Eğer ana dizinde (MyDrive) değilse, klasör adını doğru verin.\n",
        "# Varsayalım ki klasör adınız 'ParkingData'\n",
        "base_folder_name = 'parkingDataset' # <-- LÜTFEN KENDİ KLASÖR İSMİNİZİ YAZIN\n",
        "base_path = os.path.join('/content/drive/MyDrive', base_folder_name)\n",
        "\n",
        "file_names = [\n",
        "    '1t2020.csv', # Varsayım: Ocak, Şubat, Mart verileri\n",
        "    '2t2020.csv', # Varsayım: Nisan, Mayıs, Haziran verileri\n",
        "    '4t2020.csv'  # Varsayım: Ekim, Kasım, Aralık verileri\n",
        "]\n",
        "\n",
        "all_data_frames = []\n",
        "\n",
        "# --- Dosyaları Döngüyle Okuma ve Birleştirme ---\n",
        "print(\"Veri setleri okunuyor ve birleştiriliyor...\")\n",
        "for name in file_names:\n",
        "    file_path = os.path.join(base_path, name)\n",
        "    try:\n",
        "        # CSV'yi okurken formatı belirtmek faydalı olabilir\n",
        "        df_temp = pd.read_csv(file_path,sep=\";\")\n",
        "        all_data_frames.append(df_temp)\n",
        "        print(f\"'{name}' başarıyla yüklendi. Boyut: {df_temp.shape}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"UYARI: '{name}' dosyası bulunamadı. Lütfen dosya yolunu kontrol edin.\")\n",
        "    except Exception as e:\n",
        "        print(f\"'{name}' okunurken hata oluştu: {e}\")\n",
        "\n",
        "# Tüm veri setlerini tek bir DataFrame'de birleştirme\n",
        "if all_data_frames:\n",
        "    df_full = pd.concat(all_data_frames, ignore_index=True)\n",
        "    print(\"\\n--- BİRLEŞTİRİLMİŞ VERİ SETİNİN İLK 5 SATIRI ---\")\n",
        "    print(df_full.head())\n",
        "    print(f\"\\nToplam Satır Sayısı: {len(df_full)}\")\n",
        "else:\n",
        "    print(\"Hata: Hiçbir dosya başarıyla yüklenemedi. İşleme devam edilemez.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQsaofXfh_ZB",
        "outputId": "c49e8521-a021-414b-c3fa-858b5d0f5622"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Veri setleri okunuyor ve birleştiriliyor...\n",
            "'1t2020.csv' başarıyla yüklendi. Boyut: (100000, 7)\n",
            "'2t2020.csv' başarıyla yüklendi. Boyut: (100039, 7)\n",
            "'4t2020.csv' başarıyla yüklendi. Boyut: (100000, 7)\n",
            "\n",
            "--- BİRLEŞTİRİLMİŞ VERİ SETİNİN İLK 5 SATIRI ---\n",
            "  id_park                 name  max_capacity  occupancy  \\\n",
            "0    P028     Chão do Loureiro           192          0   \n",
            "1    P044   Telheiras Nascente           109         25   \n",
            "2    P013           Monumental           277        195   \n",
            "3    P004      Atrium Saldanha           251          0   \n",
            "4    P040  Mercado de Alvalade           118         88   \n",
            "\n",
            "                                            position          datetime  \\\n",
            "0  {'coordinates': [-9.135017, 38.712416], 'type'...  31/12/2019 23:59   \n",
            "1  {'coordinates': [-9.164886, 38.761512], 'type'...  31/12/2019 23:59   \n",
            "2  {'coordinates': [-9.14430800000002, 38.734036]...  31/12/2019 23:59   \n",
            "3  {'coordinates': [-9.1446021616448, 38.73326873...  31/12/2019 23:59   \n",
            "4  {'coordinates': [-9.139498, 38.755424], 'type'...  01/01/2020 00:03   \n",
            "\n",
            "          entity_ts  \n",
            "0  2020/01/01 00:00  \n",
            "1  2020/01/01 00:00  \n",
            "2  2020/01/01 00:00  \n",
            "3  2020/01/01 00:01  \n",
            "4  2020/01/01 00:05  \n",
            "\n",
            "Toplam Satır Sayısı: 300039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Mevcut Sütun İsimleri ---\")\n",
        "print(df_full.columns.tolist())\n",
        "df_full['datetime'] = pd.to_datetime(df_full['datetime'], format='%Y/%m/%d %H:%M', errors='coerce')\n",
        "df_full = df_full.drop(columns=['position', 'entity_ts'])\n",
        "df_full['hour'] = df_full['datetime'].dt.hour\n",
        "df_full['dayofweek'] = df_full['datetime'].dt.dayofweek # Pazartesi=0, Pazar=6\n",
        "df_full['is_weekend'] = (df_full['dayofweek'] >= 5).astype(int) # Hafta Sonu (Cmt/Pazar) = 1\n",
        "\n",
        "print(\"\\n--- 3. Adım Sonrası Veri Seti Bilgileri ---\")\n",
        "df_full.info()\n",
        "print(\"\\n--- Yeni Özellikler ve Son 5 Satır ---\")\n",
        "print(df_full[['datetime', 'hour', 'dayofweek', 'is_weekend', 'occupancy']].tail())\n",
        "\n",
        "# Eksik (NaT) değer olup olmadığını kontrol edelim\n",
        "missing_times = df_full['datetime'].isnull().sum()\n",
        "if missing_times > 0:\n",
        "    print(f\"\\n*** DİKKAT: {missing_times} adet geçersiz tarih/saat bulundu (NaT). Bu satırlar temizlenmelidir. ***\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H1BnrEZoNxN",
        "outputId": "0b562fb2-5b5f-47a6-d873-670012844c8a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Mevcut Sütun İsimleri ---\n",
            "['id_park', 'name', 'max_capacity', 'occupancy', 'position', 'datetime', 'entity_ts']\n",
            "\n",
            "--- 3. Adım Sonrası Veri Seti Bilgileri ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 300039 entries, 0 to 300038\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count   Dtype         \n",
            "---  ------        --------------   -----         \n",
            " 0   id_park       300039 non-null  object        \n",
            " 1   name          300039 non-null  object        \n",
            " 2   max_capacity  300039 non-null  int64         \n",
            " 3   occupancy     300039 non-null  int64         \n",
            " 4   datetime      204387 non-null  datetime64[ns]\n",
            " 5   hour          204387 non-null  float64       \n",
            " 6   dayofweek     204387 non-null  float64       \n",
            " 7   is_weekend    300039 non-null  int64         \n",
            "dtypes: datetime64[ns](1), float64(2), int64(3), object(2)\n",
            "memory usage: 18.3+ MB\n",
            "\n",
            "--- Yeni Özellikler ve Son 5 Satır ---\n",
            "                  datetime  hour  dayofweek  is_weekend  occupancy\n",
            "300034 2020-12-31 23:49:00  23.0        3.0           0         32\n",
            "300035 2020-12-31 23:49:00  23.0        3.0           0         85\n",
            "300036 2020-12-31 23:54:00  23.0        3.0           0         32\n",
            "300037 2020-12-31 23:54:00  23.0        3.0           0         26\n",
            "300038 2020-12-31 23:54:00  23.0        3.0           0         72\n",
            "\n",
            "*** DİKKAT: 95652 adet geçersiz tarih/saat bulundu (NaT). Bu satırlar temizlenmelidir. ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df_full.dropna(subset=['datetime'])\n",
        "\n",
        "# 2. Temizlenmiş Veri Setini Kontrol Etme\n",
        "print(f\"\\n--- Veri Temizleme Sonucu ---\")\n",
        "print(f\"Orijinal Satır Sayısı: {len(df_full)}\")\n",
        "print(f\"Temizlenmiş Satır Sayısı: {len(df_clean)}\")\n",
        "print(f\"Kaldırılan Kayıt Sayısı: {len(df_full) - len(df_clean)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5dVLSa2rkO3",
        "outputId": "a4fa9b2c-9485-48fd-a7ab-41fbbcc36232"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Veri Temizleme Sonucu ---\n",
            "Orijinal Satır Sayısı: 300039\n",
            "Temizlenmiş Satır Sayısı: 204387\n",
            "Kaldırılan Kayıt Sayısı: 95652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_clean.copy()\n",
        "\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "# 'id_park' sütunundaki string ifadeleri sayılara dönüştür\n",
        "df['park_id_encoded'] = le.fit_transform(df['id_park'])\n",
        "\n",
        "print(\"\\n--- Son Kontrol (Temizlenmiş Veri) ---\")\n",
        "print(df[['id_park', 'park_id_encoded', 'datetime', 'hour', 'occupancy']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8kw_yXAsEk5",
        "outputId": "617da743-4123-4a75-8509-22c2a3ff5298"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Son Kontrol (Temizlenmiş Veri) ---\n",
            "    id_park  park_id_encoded            datetime  hour  occupancy\n",
            "25     P042               33 2020-01-01 00:23:00   0.0         25\n",
            "36     P042               33 2020-01-01 00:34:00   0.0         25\n",
            "82     P042               33 2020-01-01 01:33:00   1.0         35\n",
            "97     P042               33 2020-01-01 01:44:00   1.0         40\n",
            "113    P042               33 2020-01-01 02:04:00   2.0         47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "portugal_holidays_2020 = [\n",
        "    '2020/01/01',  # Yılbaşı\n",
        "    '2020/04/10',  # Kutsal Cuma (Good Friday)\n",
        "    '2020/04/13',  # Paskalya Pazartesi (Easter Monday)\n",
        "    '2020/04/25',  # Özgürlük Günü (Freedom Day)\n",
        "    '2020/05/01',  # İşçi Bayramı (Labour Day)\n",
        "    '2020/06/10',  # Portekiz Günü (Portugal Day)\n",
        "    '2020/08/15',  # Meryem Ana'nın Göğe Alınması (Assumption of Mary)\n",
        "    '2020/10/05',  # Cumhuriyet Günü (Republic Day)\n",
        "    '2020/12/01',  # Bağımsızlık Günü (Restoration of Independence)\n",
        "    '2020/12/08',  # Kutsal Gebelik (Immaculate Conception)\n",
        "    '2020/12/25'   # Noel (Christmas Day)\n",
        "]\n",
        "df['date_only'] = df['datetime'].dt.strftime('%Y/%m/%d')\n",
        "df['is_holiday'] = df['date_only'].isin(portugal_holidays_2020).astype(int)\n",
        "df = df.drop(columns=['date_only'])\n",
        "\n",
        "# 3. Son Kontrol\n",
        "print(\"\\n--- Tatil Özelliği Kontrolü ---\")\n",
        "print(df[df['is_holiday'] == 1][['datetime', 'is_holiday', 'occupancy']].head()) # Tatil günlerinden birkaçı\n",
        "print(df[['datetime', 'hour', 'is_weekend', 'is_holiday', 'occupancy']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmc31Bb9txx5",
        "outputId": "10e233ab-09c4-4d5e-a348-1eca28046880"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Tatil Özelliği Kontrolü ---\n",
            "               datetime  is_holiday  occupancy\n",
            "25  2020-01-01 00:23:00           1         25\n",
            "36  2020-01-01 00:34:00           1         25\n",
            "82  2020-01-01 01:33:00           1         35\n",
            "97  2020-01-01 01:44:00           1         40\n",
            "113 2020-01-01 02:04:00           1         47\n",
            "               datetime  hour  is_weekend  is_holiday  occupancy\n",
            "25  2020-01-01 00:23:00   0.0           0           1         25\n",
            "36  2020-01-01 00:34:00   0.0           0           1         25\n",
            "82  2020-01-01 01:33:00   1.0           0           1         35\n",
            "97  2020-01-01 01:44:00   1.0           0           1         40\n",
            "113 2020-01-01 02:04:00   2.0           0           1         47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install meteostat\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLiS7wQ5sGAp",
        "outputId": "581ece6e-4222-4f38-da4b-9d249ba5a623"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: meteostat in /usr/local/lib/python3.12/dist-packages (1.7.6)\n",
            "Requirement already satisfied: pandas>=2 in /usr/local/lib/python3.12/dist-packages (from meteostat) (2.2.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from meteostat) (2025.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from meteostat) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2->meteostat) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2->meteostat) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2->meteostat) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Lizbon Merkezi Koordinatlarını Belirle\n",
        "LAT = 38.7223\n",
        "LON = -9.1393\n",
        "ALT = 110\n",
        "\n",
        "# 3. Meteostat için Nokta Tanımlama\n",
        "location = Point(LAT, LON, ALT)\n",
        "start_date = df['datetime'].min().date()\n",
        "end_date = df['datetime'].max().date()\n",
        "\n",
        "print(f\"Hava durumu verisi çekilecek tarih aralığı: {start_date} -> {end_date}\")\n",
        "\n",
        "start_dt = datetime.strptime(str(start_date), '%Y-%m-%d')\n",
        "end_dt = datetime.strptime(str(end_date), '%Y-%m-%d')\n",
        "\n",
        "# Saatlik veri çekme\n",
        "data = Hourly(location, start_dt, end_dt)\n",
        "data = data.fetch()\n",
        "\n",
        "# Hava Durumu DataFrame'i\n",
        "weather_df = data[['temp', 'prcp', 'wspd', 'pres']].copy()\n",
        "weather_df.index.name = 'datetime'\n",
        "\n",
        "print(f\"\\nÇekilen Saatlik Hava Durumu Kayıt Sayısı: {len(weather_df)}\")\n",
        "\n",
        "# 4. Yuvarlama\n",
        "df['rounded_datetime'] = df['datetime'].dt.floor('H')\n",
        "weather_df.index = weather_df.index.floor('H')\n",
        "\n",
        "# 5. Hava Durumu Verilerini Ana DataFrame ile Birleştirme (SUFFIXES EKLENDİ)\n",
        "# Sonek ekleyerek çakışan isimleri (temp, prcp vb.) ayırıyoruz.\n",
        "# Meteostat'tan gelenleri '_wx' (Weather Extension) ile işaretleyelim.\n",
        "df_merged = df.merge(weather_df,\n",
        "                     left_on='rounded_datetime',\n",
        "                     right_index=True,\n",
        "                     how='left',\n",
        "                     suffixes=('', '_wx')) # Orijinal sütunlara suffix eklenmez, yeni gelenlere '_wx' eklenir.\n",
        "\n",
        "# Geçici ve gereksiz sütunları temizleme\n",
        "df_merged = df_merged.drop(columns=['rounded_datetime'])\n",
        "\n",
        "# Güncel DataFrame'imizi df olarak yeniden atayalım\n",
        "df = df_merged.copy()\n",
        "\n",
        "print(\"\\n--- Hava Durumu Entegrasyonu Sonrası İlk 5 Satır Kontrolü ---\")\n",
        "# Yeni sütunlar temp_wx, prcp_wx vb. olarak gelmeli\n",
        "print(df[['datetime', 'hour', 'is_holiday', 'temp_wx', 'prcp_wx', 'occupancy']].head())\n",
        "print(\"\\n--- Entegre Veri Seti Bilgileri (Yeni Sütunlar Görünmeli) ---\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9ws0HMvvznr",
        "outputId": "74c7d6c9-73a9-4a2f-ca8c-119e3bdb5b6a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hava durumu verisi çekilecek tarih aralığı: 2020-01-01 -> 2020-12-31\n",
            "\n",
            "Çekilen Saatlik Hava Durumu Kayıt Sayısı: 8761\n",
            "\n",
            "--- Hava Durumu Entegrasyonu Sonrası İlk 5 Satır Kontrolü ---\n",
            "               datetime  hour  is_holiday  temp_wx  prcp_wx  occupancy\n",
            "25  2020-01-01 00:23:00   0.0           1      7.0      0.0         25\n",
            "36  2020-01-01 00:34:00   0.0           1      7.0      0.0         25\n",
            "82  2020-01-01 01:33:00   1.0           1      8.0     <NA>         35\n",
            "97  2020-01-01 01:44:00   1.0           1      8.0     <NA>         40\n",
            "113 2020-01-01 02:04:00   2.0           1      8.0     <NA>         47\n",
            "\n",
            "--- Entegre Veri Seti Bilgileri (Yeni Sütunlar Görünmeli) ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 204387 entries, 25 to 300038\n",
            "Data columns (total 26 columns):\n",
            " #   Column           Non-Null Count   Dtype         \n",
            "---  ------           --------------   -----         \n",
            " 0   id_park          204387 non-null  object        \n",
            " 1   name             204387 non-null  object        \n",
            " 2   max_capacity     204387 non-null  int64         \n",
            " 3   occupancy        204387 non-null  int64         \n",
            " 4   datetime         204387 non-null  datetime64[ns]\n",
            " 5   hour             204387 non-null  float64       \n",
            " 6   dayofweek        204387 non-null  float64       \n",
            " 7   is_weekend       204387 non-null  int64         \n",
            " 8   park_id_encoded  204387 non-null  int64         \n",
            " 9   is_holiday       204387 non-null  int64         \n",
            " 10  temp_x           203723 non-null  Float64       \n",
            " 11  prcp_x           21339 non-null   Float64       \n",
            " 12  wspd_x           203723 non-null  Float64       \n",
            " 13  pres_x           203723 non-null  Float64       \n",
            " 14  temp_y           203723 non-null  Float64       \n",
            " 15  prcp_y           21339 non-null   Float64       \n",
            " 16  wspd_y           203723 non-null  Float64       \n",
            " 17  pres_y           203723 non-null  Float64       \n",
            " 18  temp             203723 non-null  Float64       \n",
            " 19  prcp             21339 non-null   Float64       \n",
            " 20  wspd             203723 non-null  Float64       \n",
            " 21  pres             203723 non-null  Float64       \n",
            " 22  temp_wx          203723 non-null  Float64       \n",
            " 23  prcp_wx          21339 non-null   Float64       \n",
            " 24  wspd_wx          203723 non-null  Float64       \n",
            " 25  pres_wx          203723 non-null  Float64       \n",
            "dtypes: Float64(16), datetime64[ns](1), float64(2), int64(5), object(2)\n",
            "memory usage: 45.2+ MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_keep = [\n",
        "    'id_park', 'name', 'max_capacity', 'occupancy', 'datetime',\n",
        "    'hour', 'dayofweek', 'is_weekend', 'is_holiday', 'park_id_encoded',\n",
        "    'temp_wx', 'prcp_wx', 'wspd_wx', 'pres_wx'\n",
        "]\n",
        "\n",
        "current_cols = df.columns.tolist()\n",
        "final_cols_to_keep = [col for col in cols_to_keep if col in current_cols]\n",
        "\n",
        "# Sadece temizlenmiş sütunları tutan yeni bir DataFrame oluşturalım\n",
        "df_clean = df[final_cols_to_keep].copy()\n",
        "\n",
        "df_clean.rename(columns={\n",
        "    'temp_wx': 'temperature',\n",
        "    'prcp_wx': 'precipitation',\n",
        "    'wspd_wx': 'wind_speed',\n",
        "    'pres_wx': 'pressure'\n",
        "}, inplace=True)\n",
        "\n",
        "df_clean['occupancy_ratio'] = df_clean['occupancy'] / df_clean['max_capacity']\n",
        "\n",
        "\n",
        "# 4. Eksik Hava Durumu Değerlerini Doldurma (Imputation)\n",
        "# 'precipitation' (Yağış) sütununda çok sayıda <NA> vardı. Bunları 0.0 ile dolduralım,\n",
        "# çünkü <NA> genellikle yağış olmadığı anlamına gelir. Diğerlerini ortalama ile dolduralım.\n",
        "df_clean['precipitation'].fillna(0.0, inplace=True)\n",
        "\n",
        "for col in ['temperature', 'wind_speed', 'pressure']:\n",
        "    df_clean[col].fillna(df_clean[col].mean(), inplace=True)\n",
        "\n",
        "df = df_clean.drop(columns=['id_park', 'name', 'occupancy'])\n",
        "\n",
        "print(\"\\n--- Nihai Temizlik Sonrası Veri Seti Kontrolü ---\")\n",
        "df.info()\n",
        "print(\"\\nNihai Veri Seti Başlığı:\")\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "iyU9fcrX0MtQ",
        "outputId": "3ad82c0a-81b6-4243-b4bc-46fe2cb1d499"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'occupancy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'occupancy'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1279055838.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m }, inplace=True)\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'occupancy_ratio'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'occupancy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_capacity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'occupancy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'datetime' sütununu çıkarıyoruz, çünkü model eğitimi için sayısal özelliklere ihtiyacımız var.\n",
        "# Ayrıca modelde kullanmayacağımız ve temizlenmemiş olabilecek eski sütunları da düşürelim.\n",
        "cols_to_drop_final = ['datetime', 'occupancy', 'id_park', 'name']\n",
        "\n",
        "# Sadece mevcut olan sütunları düşürmeyi deneyeceğiz.\n",
        "current_columns = df.columns.tolist()\n",
        "cols_to_safely_drop = [col for col in cols_to_drop_final if col in current_columns]\n",
        "\n",
        "# Nihai DataFrame'i oluştur\n",
        "df_model = df.drop(columns=cols_to_safely_drop, errors='ignore').copy()\n",
        "# .copy() kullanmak FutureWarning'ı azaltmaya yardımcı olur.\n",
        "\n",
        "# 1. Özellikler (X) ve Hedef (Y) Değişkenlerini Ayırma\n",
        "TARGET = 'occupancy_ratio'\n",
        "FEATURES = [\n",
        "    'hour',\n",
        "    'dayofweek',\n",
        "    'is_weekend',\n",
        "    'is_holiday',\n",
        "    'park_id_encoded',\n",
        "    'max_capacity',\n",
        "    'temperature',\n",
        "    'precipitation',\n",
        "    'wind_speed',\n",
        "    'pressure'\n",
        "]\n",
        "\n",
        "X = df_model[FEATURES]\n",
        "Y = df_model[TARGET]\n",
        "\n",
        "# Eksik kalan 1 satırı temizleyelim (occupancy_ratio'da 1 null vardı)\n",
        "# Bu satırda hem X hem Y için aynı satırların düşürüldüğünden emin olmak için birlikte temizleyelim.\n",
        "valid_indices = Y.dropna().index\n",
        "X = X.loc[valid_indices]\n",
        "Y = Y.loc[valid_indices]\n",
        "\n",
        "print(f\"Eğitime Hazır Toplam Kayıt: {len(X)}\")\n",
        "\n",
        "# Buradan sonra Model Eğitim Koduna geçebilirsiniz\n",
        "# ----------------------------------------------------------------------\n",
        "# 2. Veri Setini Eğitim ve Test Setlerine Ayırma (Zaman Serisi)\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "Y_train, Y_test = Y[:train_size], Y[train_size:]\n",
        "\n",
        "\n",
        "# 3. Veri Ölçeklendirme (Standardizasyon)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "cols_to_scale = ['hour', 'max_capacity', 'temperature', 'precipitation', 'wind_speed', 'pressure']\n",
        "# Eğitim verisini ölçeklendir\n",
        "X_train.loc[:, cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
        "# Test verisini aynı scaler ile ölçeklendir\n",
        "X_test.loc[:, cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
        "\n",
        "\n",
        "# 4. Modeli Oluşturma ve Eğitme (Random Forest Regressor)\n",
        "\n",
        "print(\"\\n--- Model Eğitimi Başlıyor (Random Forest) ---\")\n",
        "start_time = time.time()\n",
        "\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Eğitim Tamamlandı. Süre: {end_time - start_time:.2f} saniye.\")\n",
        "\n",
        "\n",
        "# 5. Tahmin Yapma ve Değerlendirme\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))\n",
        "mae = mean_absolute_error(Y_test, Y_pred)\n",
        "\n",
        "print(\"\\n--- Model Performans Değerlendirmesi (Ratio Tahmini) ---\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "\n",
        "\n",
        "# 6. Özellik Önem Derecesi (Feature Importance)\n",
        "feature_importances = pd.Series(model.feature_importances_, index=FEATURES).sort_values(ascending=False)\n",
        "print(\"\\n--- Özellik Önem Derecesi ---\")\n",
        "print(feature_importances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9Xl2P0g1tAE",
        "outputId": "3a91d659-85f2-4c54-9dfc-01b5eefae0d6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eğitime Hazır Toplam Kayıt: 204386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.28204476 -0.28204476 -0.28204476 ... -0.50755552 -0.60864655\n",
            " -0.27426853]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 4.37851096 -0.60864655 -0.45571397 ... -0.59568616 -0.52310799\n",
            "  0.23118663]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Eğitimi Başlıyor (Random Forest) ---\n",
            "Eğitim Tamamlandı. Süre: 90.60 saniye.\n",
            "\n",
            "--- Model Performans Değerlendirmesi (Ratio Tahmini) ---\n",
            "Root Mean Squared Error (RMSE): 0.1651\n",
            "Mean Absolute Error (MAE): 0.0811\n",
            "\n",
            "--- Özellik Önem Derecesi ---\n",
            "park_id_encoded    0.546869\n",
            "max_capacity       0.215495\n",
            "pressure           0.059886\n",
            "hour               0.057291\n",
            "temperature        0.047822\n",
            "dayofweek          0.032644\n",
            "wind_speed         0.028714\n",
            "is_weekend         0.007780\n",
            "is_holiday         0.003185\n",
            "precipitation      0.000315\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_month = 7  # Temmuz\n",
        "end_month = 9    # Eylül (Eylül dahil olduğu için 9'u dahil etmeliyiz)\n",
        "year = 2020\n",
        "\n",
        "# Tahmin için gerekli olan ilk ve son saatleri belirleyelim\n",
        "# Temmuz'un ilk günü saat 00:00:00'dan başlayıp, Eylül'ün son günü saat 23:00:00'a kadar.\n",
        "pred_start_date = datetime(year, start_month, 1, 0, 0, 0)\n",
        "# Eylül 30'unun sonuna kadar veri çekmek için, Ekim 1'in başlangıcından hemen önce bitirelim.\n",
        "pred_end_date = datetime(year, end_month, 30, 23, 0, 0) # Eylül 30'a kadar\n",
        "\n",
        "# 2. Tahmin Edilecek Tarih/Saatleri Oluşturma (Park bazında)\n",
        "# Benzersiz park kimliklerini alalım (eğitim setinde kullanılan sayısal kodlar)\n",
        "unique_park_ids = df['park_id_encoded'].unique()\n",
        "\n",
        "# Tahmin edilecek tüm zaman ve park kombinasyonlarını içeren boş DataFrame oluşturma\n",
        "prediction_data = []\n",
        "current_time = pred_start_date\n",
        "\n",
        "# Her park için her saatlik veriyi oluştur\n",
        "print(\"Tahmin edilecek zaman aralığı ve park kombinasyonları oluşturuluyor...\")\n",
        "while current_time <= pred_end_date:\n",
        "    for park_id in unique_park_ids:\n",
        "        prediction_data.append({\n",
        "            'park_id_encoded': park_id,\n",
        "            'datetime': current_time\n",
        "        })\n",
        "    current_time += timedelta(hours=1) # Bir sonraki saate geç\n",
        "\n",
        "df_predict = pd.DataFrame(prediction_data)\n",
        "print(f\"Oluşturulan Tahmin Satır Sayısı: {len(df_predict)}\")\n",
        "\n",
        "\n",
        "# 3. Tahmin Edilecek Veriler İçin Zaman Özelliklerini Çıkarma\n",
        "df_predict['hour'] = df_predict['datetime'].dt.hour\n",
        "df_predict['dayofweek'] = df_predict['datetime'].dt.dayofweek\n",
        "df_predict['is_weekend'] = (df_predict['dayofweek'] >= 5).astype(int)\n",
        "\n",
        "# 4. Tatil Özelliklerini Ekleme\n",
        "# Temmuz, Ağustos ve Eylül 2020 tatillerini kontrol etmeliyiz.\n",
        "# Sizin orijinal tatil listeniz 2020'nin tamamını kapsayacak şekilde genişletilmelidir.\n",
        "portugal_holidays_2020_full = [\n",
        "    '2020/01/01', '2020/04/10', '2020/04/13', '2020/04/25', '2020/05/01',\n",
        "    '2020/06/10', '2020/08/15',  # Yaz ayındaki tek resmi tatil (15 Ağustos)\n",
        "    '2020/10/05', '2020/12/01', '2020/12/08', '2020/12/25'\n",
        "]\n",
        "df_predict['date_only'] = df_predict['datetime'].dt.strftime('%Y/%m/%d')\n",
        "df_predict['is_holiday'] = df_predict['date_only'].isin(portugal_holidays_2020_full).astype(int)\n",
        "df_predict = df_predict.drop(columns=['date_only'])\n",
        "\n",
        "print(\"Tahmin Veri Seti Hazır (İlk 5 Satır):\")\n",
        "print(df_predict.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDDcHVM_1qcP",
        "outputId": "69cf82fa-d121-4a64-a9f7-47c5fab05499"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahmin edilecek zaman aralığı ve park kombinasyonları oluşturuluyor...\n",
            "Oluşturulan Tahmin Satır Sayısı: 99360\n",
            "Tahmin Veri Seti Hazır (İlk 5 Satır):\n",
            "   park_id_encoded   datetime  hour  dayofweek  is_weekend  is_holiday\n",
            "0               33 2020-07-01     0          2           0           0\n",
            "1               35 2020-07-01     0          2           0           0\n",
            "2               27 2020-07-01     0          2           0           0\n",
            "3                1 2020-07-01     0          2           0           0\n",
            "4               10 2020-07-01     0          2           0           0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Hava Durumu Verisini Çekme ve Entegrasyon (Tekrar) ---\n",
        "\n",
        "# Bu kısımlar doğru çalışıyordu:\n",
        "# [Meteostat veri çekme kısmı...]\n",
        "# data_pred = Hourly(location, pred_start_date_weather, pred_end_date_weather).fetch()\n",
        "# ...\n",
        "\n",
        "# 1. Hava Durumu Verilerini Tahmin DataFrame'i ile Birleştirme\n",
        "df_predict_merged = df_predict.merge(weather_df_pred,\n",
        "                                     left_on='rounded_datetime',\n",
        "                                     right_index=True,\n",
        "                                     how='left',\n",
        "                                     suffixes=('_pred', ''))\n",
        "df_predict_merged = df_predict_merged.drop(columns=['rounded_datetime'])\n",
        "\n",
        "# 2. Sütun İsimlerini Düzeltme\n",
        "df_predict_merged.rename(columns={\n",
        "    'temp': 'temperature',\n",
        "    'prcp': 'precipitation',\n",
        "    'wspd': 'wind_speed',\n",
        "    'pres': 'pressure'\n",
        "}, inplace=True)\n",
        "\n",
        "# 3. max_capacity özelliğini tahmin setine ekleme (HATA DÜZELTİLDİ)\n",
        "# Hata veren satırın düzeltilmiş hali:\n",
        "# Amacımız: Her park_id_encoded için tek bir max_capacity değeri almak.\n",
        "park_capacity_map = df.groupby('park_id_encoded')['max_capacity'].first().to_dict()\n",
        "\n",
        "# Kapasiteyi yeni DataFrame'e eşleme\n",
        "df_predict_merged['max_capacity'] = df_predict_merged['park_id_encoded'].map(park_capacity_map)\n",
        "\n",
        "# Eksik kalırsa en sık kullanılan kapasite ile doldur (güvenlik için)\n",
        "df_predict_merged['max_capacity'].fillna(df['max_capacity'].mode().iloc[0], inplace=True)\n",
        "df_predict_merged['max_capacity'] = df_predict_merged['max_capacity'].astype(int) # Tam sayıya çevirme\n",
        "\n",
        "\n",
        "# 4. Eksik Hava Durumu Değerlerini Doldurma (Imputation)\n",
        "df_predict_merged['precipitation'].fillna(0.0, inplace=True)\n",
        "\n",
        "for col in ['temperature', 'wind_speed', 'pressure']:\n",
        "    df_predict_merged[col].fillna(df_predict_merged[col].mean(), inplace=True)\n",
        "\n",
        "\n",
        "# 5. Özellikleri Ölçeklendirme (Eğitimde kullanılan scaler ile)\n",
        "cols_to_scale_full = ['hour', 'max_capacity', 'temperature', 'precipitation', 'wind_speed', 'pressure']\n",
        "X_new_scaled = df_predict_merged[cols_to_scale_full].copy()\n",
        "\n",
        "# .loc kullanarak warning'i azaltma ve güvenli ölçekleme\n",
        "X_new_scaled.loc[:, cols_to_scale_full] = scaler.transform(X_new_scaled[cols_to_scale_full])\n",
        "\n",
        "# Geri kalan özellikleri birleştirip tahmin setini oluşturalım\n",
        "X_new_other = df_predict_merged[['dayofweek', 'is_weekend', 'is_holiday', 'park_id_encoded']]\n",
        "\n",
        "# X_new için sadece gerekli sütunları birleştirelim.\n",
        "# Önemli: Concatenation'dan sonra, sütun sırasını modelin beklediği hale getireceğiz.\n",
        "X_new_temp = pd.concat([X_new_other.reset_index(drop=True), X_new_scaled.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Sütun sırasını modelin beklediği \"FEATURES\" listesiyle eşitleme\n",
        "FEATURES = [\n",
        "    'hour', 'dayofweek', 'is_weekend', 'is_holiday', 'park_id_encoded',\n",
        "    'max_capacity', 'temperature', 'precipitation', 'wind_speed', 'pressure'\n",
        "]\n",
        "X_new = X_new_temp[FEATURES]\n",
        "\n",
        "\n",
        "# 6. Tahmin Yapma\n",
        "Y_predicted_ratio = model.predict(X_new)\n",
        "\n",
        "# 7. Sonuçları DataFrame'e Ekleme\n",
        "df_predict_merged['predicted_occupancy_ratio'] = Y_predicted_ratio\n",
        "df_predict_merged['predicted_occupancy'] = (df_predict_merged['predicted_occupancy_ratio'] * df_predict_merged['max_capacity']).round().astype(int)\n",
        "\n",
        "\n",
        "print(\"\\n--- Tahmin Sonuçları (Temmuz Başı) ---\")\n",
        "print(df_predict_merged[df_predict_merged['datetime'].dt.month == 7][['datetime', 'park_id_encoded', 'max_capacity', 'temperature', 'predicted_occupancy_ratio', 'predicted_occupancy']].head(15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a7BStka5EtU",
        "outputId": "7c142472-93f0-4014-f8d3-40fb09631f74"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.65252201 -1.65252201 -1.65252201 ...  1.65946535  1.65946535\n",
            "  1.65946535]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
            "FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.28204476 -0.52310799 -0.39091202 ...  0.27006779  0.42300038\n",
            " -0.16280919]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Tahmin Sonuçları (Temmuz Başı) ---\n",
            "     datetime  park_id_encoded  max_capacity  temperature  \\\n",
            "0  2020-07-01               33           202         19.0   \n",
            "1  2020-07-01               35           109         19.0   \n",
            "2  2020-07-01               27           160         19.0   \n",
            "3  2020-07-01                1           400         19.0   \n",
            "4  2020-07-01               10           277         19.0   \n",
            "5  2020-07-01               14           240         19.0   \n",
            "6  2020-07-01               31           118         19.0   \n",
            "7  2020-07-01               36            98         19.0   \n",
            "8  2020-07-01               19            76         19.0   \n",
            "9  2020-07-01               25           248         19.0   \n",
            "10 2020-07-01               29            81         19.0   \n",
            "11 2020-07-01               16          2000         19.0   \n",
            "12 2020-07-01                3           251         19.0   \n",
            "13 2020-07-01                5           255         19.0   \n",
            "14 2020-07-01               17           135         19.0   \n",
            "\n",
            "    predicted_occupancy_ratio  predicted_occupancy  \n",
            "0                    0.394214                   80  \n",
            "1                    0.218807                   24  \n",
            "2                    0.204879                   33  \n",
            "3                    0.291677                  117  \n",
            "4                    0.703971                  195  \n",
            "5                    0.641656                  154  \n",
            "6                    0.685532                   81  \n",
            "7                    0.295918                   29  \n",
            "8                    0.947050                   72  \n",
            "9                    0.362306                   90  \n",
            "10                   0.509490                   41  \n",
            "11                   0.502497                 1005  \n",
            "12                   0.106534                   27  \n",
            "13                   0.562275                  143  \n",
            "14                   0.195670                   26  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ORIGINAL_FEATURES = [\n",
        "    'datetime', 'hour', 'dayofweek', 'is_weekend', 'is_holiday',\n",
        "    'park_id_encoded', 'max_capacity', 'temperature', 'precipitation',\n",
        "    'wind_speed', 'pressure', 'occupancy_ratio'\n",
        "]\n",
        "\n",
        "# Orijinal (Temmuz-Eylül dışındaki) veriyi filtrele\n",
        "# df, model eğitiminden önceki temizlenmiş orijinal DataFrame'inizdir.\n",
        "df_clean_original = df[\n",
        "    (df['datetime'].dt.month < 7) | (df['datetime'].dt.month > 9)\n",
        "].copy()\n",
        "\n",
        "# Sadece ihtiyacımız olan kolonları tutalım\n",
        "df_clean_original = df_clean_original[ORIGINAL_FEATURES]\n",
        "\n",
        "\n",
        "# 2. Tahmin Verisini Hazırlama\n",
        "# df_predict_merged, tahmin sonuçlarının olduğu DataFrame'inizdir.\n",
        "PREDICTED_FEATURES = [\n",
        "    'datetime', 'park_id_encoded', 'max_capacity',\n",
        "    'hour', 'dayofweek', 'is_weekend', 'is_holiday',\n",
        "    'temperature', 'precipitation', 'wind_speed', 'pressure',\n",
        "    'predicted_occupancy_ratio' # Tahmin edilen oran\n",
        "]\n",
        "\n",
        "df_predicted_final = df_predict_merged[PREDICTED_FEATURES].copy()\n",
        "\n",
        "# Sütun adlarını orijinal formata çevirme\n",
        "df_predicted_final.rename(columns={'predicted_occupancy_ratio': 'occupancy_ratio'}, inplace=True)\n",
        "\n",
        "\n",
        "# 3. İki Veri Setini Birleştirme (Union)\n",
        "final_data = pd.concat([df_clean_original, df_predicted_final], ignore_index=True)\n",
        "\n",
        "# Veriyi tarih/zamana göre sıralama\n",
        "final_data = final_data.sort_values(by=['datetime', 'park_id_encoded']).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"\\n--- Nihai Birleştirilmiş Veri Seti Kontrolü (TÜM ÖZELLİKLERLE) ---\")\n",
        "print(f\"Toplam Satır Sayısı: {len(final_data)}\")\n",
        "print(\"Sütunlar:\")\n",
        "print(final_data.columns.tolist())\n",
        "print(\"\\nTemmuz Tahmin Başlangıcı:\")\n",
        "print(final_data[final_data['datetime'].dt.month == 7].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T90Dn7bF66Rj",
        "outputId": "d47bf15f-e569-47bc-f3ba-1375f0de22a7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Nihai Birleştirilmiş Veri Seti Kontrolü (TÜM ÖZELLİKLERLE) ---\n",
            "Toplam Satır Sayısı: 303747\n",
            "Sütunlar:\n",
            "['datetime', 'hour', 'dayofweek', 'is_weekend', 'is_holiday', 'park_id_encoded', 'max_capacity', 'temperature', 'precipitation', 'wind_speed', 'pressure', 'occupancy_ratio']\n",
            "\n",
            "Temmuz Tahmin Başlangıcı:\n",
            "         datetime  hour  dayofweek  is_weekend  is_holiday  park_id_encoded  \\\n",
            "104387 2020-07-01   0.0        2.0           0           0                0   \n",
            "104388 2020-07-01   0.0        2.0           0           0                1   \n",
            "104389 2020-07-01   0.0        2.0           0           0                2   \n",
            "104390 2020-07-01   0.0        2.0           0           0                3   \n",
            "104391 2020-07-01   0.0        2.0           0           0                4   \n",
            "\n",
            "        max_capacity  temperature  precipitation  wind_speed  pressure  \\\n",
            "104387          1145         19.0            0.0        20.5    1015.0   \n",
            "104388           400         19.0            0.0        20.5    1015.0   \n",
            "104389           503         19.0            0.0        20.5    1015.0   \n",
            "104390           251         19.0            0.0        20.5    1015.0   \n",
            "104391           503         19.0            0.0        20.5    1015.0   \n",
            "\n",
            "        occupancy_ratio  \n",
            "104387         0.291677  \n",
            "104388         0.291677  \n",
            "104389         0.291677  \n",
            "104390         0.106534  \n",
            "104391         0.398912  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.to_csv('2020_Park_Doluluk_Tahmin_Tamamlandi.csv', index=False)\n",
        "print(\"Nihai veri seti başarıyla kaydedildi: 2020_Park_Doluluk_Tahmin_Tamamlandi.csv\")\n",
        "df_new=pd.read_csv('2020_Park_Doluluk_Tahmin_Tamamlandi.csv')\n",
        "df_new.head()\n",
        "#df_new.info()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "qJRgcNOn8DEw",
        "outputId": "3a9780e5-c706-4b3f-e1e3-334986f8ecbd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nihai veri seti başarıyla kaydedildi: 2020_Park_Doluluk_Tahmin_Tamamlandi.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              datetime  hour  dayofweek  is_weekend  is_holiday  \\\n",
              "0  2020-01-01 00:23:00   0.0        2.0           0           1   \n",
              "1  2020-01-01 00:34:00   0.0        2.0           0           1   \n",
              "2  2020-01-01 01:33:00   1.0        2.0           0           1   \n",
              "3  2020-01-01 01:44:00   1.0        2.0           0           1   \n",
              "4  2020-01-01 02:04:00   2.0        2.0           0           1   \n",
              "\n",
              "   park_id_encoded  max_capacity  temperature  precipitation  wind_speed  \\\n",
              "0               33           202          7.0            0.0         3.6   \n",
              "1               33           202          7.0            0.0         3.6   \n",
              "2               33           202          8.0            0.0         9.4   \n",
              "3               33           202          8.0            0.0         9.4   \n",
              "4               33           202          8.0            0.0         9.4   \n",
              "\n",
              "   pressure  occupancy_ratio  \n",
              "0    1031.0         0.123762  \n",
              "1    1031.0         0.123762  \n",
              "2    1031.0         0.173267  \n",
              "3    1031.0         0.198020  \n",
              "4    1030.0         0.232673  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc06ceb8-ed57-4d19-bcd9-3da93afb9d5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>hour</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>is_weekend</th>\n",
              "      <th>is_holiday</th>\n",
              "      <th>park_id_encoded</th>\n",
              "      <th>max_capacity</th>\n",
              "      <th>temperature</th>\n",
              "      <th>precipitation</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>pressure</th>\n",
              "      <th>occupancy_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-01 00:23:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>202</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1031.0</td>\n",
              "      <td>0.123762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-01 00:34:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>202</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1031.0</td>\n",
              "      <td>0.123762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-01 01:33:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>202</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>1031.0</td>\n",
              "      <td>0.173267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-01 01:44:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>202</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>1031.0</td>\n",
              "      <td>0.198020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-01 02:04:00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>202</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>1030.0</td>\n",
              "      <td>0.232673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc06ceb8-ed57-4d19-bcd9-3da93afb9d5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc06ceb8-ed57-4d19-bcd9-3da93afb9d5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc06ceb8-ed57-4d19-bcd9-3da93afb9d5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-430d460c-5681-44d4-af26-60d74f6ab109\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-430d460c-5681-44d4-af26-60d74f6ab109')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-430d460c-5681-44d4-af26-60d74f6ab109 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#df_new\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2020-01-01 00:34:00\",\n          \"2020-01-01 02:04:00\",\n          \"2020-01-01 01:33:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8366600265340756,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dayofweek\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 2.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_weekend\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_holiday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"park_id_encoded\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 33,\n        \"max\": 33,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_capacity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 202,\n        \"max\": 202,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          202\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477225575051662,\n        \"min\": 7.0,\n        \"max\": 8.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          8.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precipitation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wind_speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.1767908335299637,\n        \"min\": 3.6,\n        \"max\": 9.4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4472135954999579,\n        \"min\": 1030.0,\n        \"max\": 1031.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupancy_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04743183986932073,\n        \"min\": 0.1237623762376237,\n        \"max\": 0.2326732673267326,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.1732673267326732\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1W3cBW5fXUsZeJCwZoS7rJGYl-pvrsgTp",
      "authorship_tag": "ABX9TyMsfxfNqbe4eCN98kuNTMRR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}